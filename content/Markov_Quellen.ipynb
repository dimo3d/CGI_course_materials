{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Einführung in Markov-Quellen\n\n## Was ist eine Markov-Quelle?\n\nIm Bereich der Informationstheorie ist eine **Markov-Quelle** ein statistisches Modell, das eine Sequenz von Symbolen ausgibt, basierend auf Wahrscheinlichkeiten, die vom vorherigen Symbol in der Sequenz abhängen. Diese Abhängigkeit führt das Konzept des 'Gedächtnisses' in die Quelle ein, da das nächste Symbol nicht unabhängig von den vorherigen Symbolen ist.\n\n## Bedeutung in der Informationstheorie\n\nMarkov-Quellen sind grundlegend für das Verständnis vieler Aspekte der Datenkompression, Kanalkodierung und Vorhersage von Ereignissequenzen. Sie bieten ein Rahmenwerk für die Modellierung der Wahrscheinlichkeiten von Sequenzen in einem Prozess über die Zeit, was für die Gestaltung effizienter Kodierungsschemata entscheidend ist.\n\n## Ziel dieses Notebooks\n\nIn diesem Notebook untersuchen wir eine Markov-Quelle der Ordnung 1, was bedeutet, dass die Wahrscheinlichkeit eines aktuellen Symbols nur vom unmittelbar vorhergehenden Symbol abhängt. Angesichts eines Alphabets \\( X = \\{x_1, x_2, x_3\\} \\) und einer Übergangswahrscheinlichkeitsmatrix ist unser Ziel, die stationären Wahrscheinlichkeiten jedes Symbols im Alphabet zu bestimmen. Dies wird es uns ermöglichen, das Langzeitverhalten der Markov-Quelle zu verstehen.\n\nAm Ende dieser Übung werden wir ein klareres Verständnis dafür haben, wie Quellen mit Gedächtnis funktionieren und wie man wichtige Wahrscheinlichkeiten berechnet, die ihr Verhalten definieren.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Theoretische Grundlagen\n\n## Markov-Quellen mit Gedächtnis\n\nMarkov-Quellen mit Gedächtnis, speziell Markov-Quellen der Ordnung 1, haben die Besonderheit, dass die Wahrscheinlichkeit eines aktuellen Symbols $ Z_i $ von seinem Vorgänger $ Z_{i-1}$ abhängt. Dieses Konzept wird mathematisch durch eine Übergangswahrscheinlichkeitsmatrix dargestellt.\n\n### Übergangswahrscheinlichkeitsmatrix (P)\n\nFür ein Alphabet $ X = \\{x_1, x_2, x_3\\} $ beschreibt die Matrix $ P$ die Wahrscheinlichkeiten eines Übergangs von einem Symbol zu einem anderen. Die Matrix ist wie folgt aufgebaut:\n\n$$\nP = \\begin{bmatrix}\nP(Z_1|Z_1) & P(Z_1|Z_2) & P(Z_1|Z_3) \\\\\nP(Z_2|Z_1) & P(Z_2|Z_2) & P(Z_2|Z_3) \\\\\nP(Z_3|Z_1) & P(Z_3|Z_2) & P(Z_3|Z_3) \\\\\n\\end{bmatrix} \n$$\n\n### Stationäre Wahrscheinlichkeiten (π)\n\nDie stationären Wahrscheinlichkeiten $ \\pi = \\{P(Z_1), P(Z_2), P(Z_3)\\} $ repräsentieren den langfristigen Anteil der Zeit, den die Quelle in jedem Zustand verbringt. Sie können als Lösungen des folgenden linearen Gleichungssystems gefunden werden:\n\n1. $ P(Z_1) = P(Z_1|Z_1) \\cdot P(Z_1) + P(Z_1|Z_2) \\cdot P(Z_2) + P(Z_1|Z_3) \\cdot P(Z_3) $\n2. $ P(Z_2) = P(Z_2|Z_1) \\cdot P(Z_1) + P(Z_2|Z_2) \\cdot P(Z_2) + P(Z_2|Z_3) \\cdot P(Z_3) $\n3. $ P(Z_3) = P(Z_3|Z_1) \\cdot P(Z_1) + P(Z_3|Z_2) \\cdot P(Z_2) + P(Z_3|Z_3) \\cdot P(Z_3) $\n4. $ P(Z_1) + P(Z_2) + P(Z_3) = 1 $\n\n### Berechnung\n\nUm die stationären Wahrscheinlichkeiten zu bestimmen, müssen wir das obige Gleichungssystem lösen, wobei die letzte Gleichung die Normalisierungsbedingung darstellt, dass die Gesamtwahrscheinlichkeit 1 sein muss. Die Lösung dieses Systems gibt uns die langfristigen Wahrscheinlichkeiten für das Auftreten jedes Symbols in der Markov-Quelle.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sympy import Matrix\n\n# Create a matrix from the transition probabilities and subtract it from an identity matrix\n# This will create the system of equations (I - P') * π = 0 where π is the steady state distribution vector\n# We need to replace one of the equations with the normalization condition π1 + π2 + π3 = 1\n\n# Define the transition probability matrix\nP = Matrix([[0.8, 0.1, 0.1], [0.4, 0.2, 0.4], [0.1, 0.3, 0.6]])",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Aufstellung der Gleichungen\n\nUm die stationären Wahrscheinlichkeiten für eine Markov-Quelle zu finden, nutzen wir die Eigenschaften der Übergangswahrscheinlichkeitsmatrix und die Tatsache, dass im Gleichgewicht die Wahrscheinlichkeiten konstant bleiben.\n\n## System der Gleichungen\n\nFür eine Markov-Quelle der Ordnung 1 mit drei möglichen Zuständen $ Z_1, Z_2, Z_3 $ und der Übergangswahrscheinlichkeitsmatrix $ P $ erstellen wir ein System linearer Gleichungen. Jede Gleichung entspricht einem Zustand der Markov-Quelle und beschreibt, dass die Wahrscheinlichkeit, in diesen Zustand zu gelangen, gleich der Wahrscheinlichkeit ist, diesen Zustand zu verlassen.\n\n## Subtraktion der Matrix von der Einheitsmatrix\n\nUm das Gleichungssystem aufzustellen, subtrahieren wir die transponierte Übergangswahrscheinlichkeitsmatrix $ P^T $ von der Einheitsmatrix $ I $. Dies ergibt eine neue Matrix $ A $, die wir zur Lösung des Gleichungssystems verwenden können.\n\n$$ A = I - P^T $$\n\n## Normalisierungsbedingung\n\nDa die Summe aller Wahrscheinlichkeiten 1 ergeben muss, ersetzen wir eine der Zeilen in $ A $ durch die Normalisierungsbedingung. Das ergibt das finale Gleichungssystem, welches wir lösen werden, um die stationären Wahrscheinlichkeiten $ pi $ zu bestimmen.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sympy import symbols, Eq, solve, Matrix\n\n# Define the transition probability matrix for a source of order 1\nP = Matrix([[0.8, 0.1, 0.1], [0.4, 0.2, 0.4], [0.1, 0.3, 0.6]])\n\n# Set up the system of equations for the steady state probabilities\n# We create a system (I - P') * π = 0 and replace one row with the normalization condition\nI = Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\nA = I - P.transpose()\nA[2, :] = Matrix([[1, 1, 1]])  # Replace the last row with the normalization condition\nb = Matrix([0, 0, 1])  # Result matrix for the equations\n\n# Solve the system for the steady state distribution π\nsteady_state_distribution = A.solve_least_squares(b)\nsteady_state_distribution\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Matrix([\n[0.512820512820512],\n[ 0.17948717948718],\n[0.307692307692308]])",
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}0.512820512820512\\\\0.17948717948718\\\\0.307692307692308\\end{matrix}\\right]$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}